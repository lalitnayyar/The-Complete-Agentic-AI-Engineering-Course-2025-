{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Are you ready for action??</h2>\n",
    "            <span style=\"color:#ff7800;\">Have you completed all the setup steps in the <a href=\"../setup/\">setup</a> folder?<br/>\n",
    "            Have you read the <a href=\"../README.md\">README</a>? Many common questions are answered here!<br/>\n",
    "            Have you checked out the guides in the <a href=\"../guides/01_intro.ipynb\">guides</a> folder?<br/>\n",
    "            Well in that case, you're ready!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">This code is a live resource - keep an eye out for my updates</h2>\n",
    "            <span style=\"color:#00bfff;\">I push updates regularly. As people ask questions or have problems, I add more examples and improve explanations. As a result, the code below might not be identical to the videos, as I've added more steps and better comments. Consider this like an interactive book that accompanies the lectures.<br/><br/>\n",
    "            I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And please do remember to contact me if I can help\n",
    "\n",
    "And I love to connect: https://www.linkedin.com/in/eddonner/\n",
    "\n",
    "\n",
    "### New to Notebooks like this one? Head over to the guides folder!\n",
    "\n",
    "Just to check you've already added the Python and Jupyter extensions to Cursor, if not already installed:\n",
    "- Open extensions (View >> extensions)\n",
    "- Search for python, and when the results show, click on the ms-python one, and Install it if not already installed\n",
    "- Search for jupyter, and when the results show, click on the Microsoft one, and Install it if not already installed  \n",
    "Then View >> Explorer to bring back the File Explorer.\n",
    "\n",
    "And then:\n",
    "1. Click where it says \"Select Kernel\" near the top right, and select the option called `.venv (Python 3.12.9)` or similar, which should be the first choice or the most prominent choice. You may need to choose \"Python Environments\" first.\n",
    "2. Click in each \"cell\" below, starting with the cell immediately below this text, and press Shift+Enter to run\n",
    "3. Enjoy!\n",
    "\n",
    "After you click \"Select Kernel\", if there is no option like `.venv (Python 3.12.9)` then please do the following:  \n",
    "1. On Mac: From the Cursor menu, choose Settings >> VS Code Settings (NOTE: be sure to select `VSCode Settings` not `Cursor Settings`);  \n",
    "On Windows PC: From the File menu, choose Preferences >> VS Code Settings(NOTE: be sure to select `VSCode Settings` not `Cursor Settings`)  \n",
    "2. In the Settings search bar, type \"venv\"  \n",
    "3. In the field \"Path to folder with a list of Virtual Environments\" put the path to the project root, like C:\\Users\\username\\projects\\agents (on a Windows PC) or /Users/username/projects/agents (on Mac or Linux).  \n",
    "And then try again.\n",
    "\n",
    "Having problems with missing Python versions in that list? Have you ever used Anaconda before? It might be interferring. Quit Cursor, bring up a new command line, and make sure that your Anaconda environment is deactivated:    \n",
    "`conda deactivate`  \n",
    "And if you still have any problems with conda and python versions, it's possible that you will need to run this too:  \n",
    "`conda config --set auto_activate_base false`  \n",
    "and then from within the Agents directory, you should be able to run `uv python list` and see the Python 3.12 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import. If you get an Import Error, double check that your Kernel is correct..\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "# If this returns false, see the next cell!\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait, did that just output `False`??\n",
    "\n",
    "If so, the most common reason is that you didn't save your `.env` file after adding the key! Be sure to have saved.\n",
    "\n",
    "Also, make sure the `.env` file is named precisely `.env` and is in the project root directory (`agents`)\n",
    "\n",
    "By the way, your `.env` file should have a stop symbol next to it in Cursor on the left, and that's actually a good thing: that's Cursor saying to you, \"hey, I realize this is a file filled with secret information, and I'm not going to send it to an external AI to suggest changes, because your keys should not be shown to anyone else.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Final reminders</h2>\n",
    "            <span style=\"color:#ff7800;\">1. If you're not confident about Environment Variables or Web Endpoints / APIs, please read Topics 3 and 5 in this <a href=\"../guides/04_technical_foundations.ipynb\">technical foundations guide</a>.<br/>\n",
    "            2. If you want to use AIs other than OpenAI, like Gemini, DeepSeek or Ollama (free), please see the first section in this <a href=\"../guides/09_ai_apis_and_ollama.ipynb\">AI APIs guide</a>.<br/>\n",
    "            3. If you ever get a Name Error in Python, you can always fix it immediately; see the last section of this <a href=\"../guides/06_python_foundations.ipynb\">Python Foundations guide</a> and follow both tutorials and exercises.<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.\n",
    "\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting in the Setup folder\n",
    "# Even for other LLM providers like Gemini, you still use this OpenAI import - see Guide 9 for why\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's correct! \\(2 + 2 = 4\\). If you have any more math questions or need help with something else, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "# The APIs guide (guide 9) has exact instructions for using even cheaper or free alternatives to OpenAI\n",
    "# If you get a NameError, head to the guides folder (guide 6) to learn about NameErrors - always instantly fixable\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - let's ask for a question:\n",
    "\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you rearrange the letters of the word \"CONVERSATION,\" how many unique new English words of exactly 10 letters can you form that use all the letters except one?\n"
     ]
    }
   ],
   "source": [
    "# ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's correct! \\(2 + 2 = 4\\). If you have any other math questions or need help with anything else, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Ask it again\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "That's correct! \\(2 + 2 = 4\\). If you have any other math questions or need help with anything else, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(answer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "That was a small, simple step in the direction of Agentic AI, with your new environment!\n",
    "\n",
    "Next time things get more interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution. <br/>\n",
    "            We will cover this at up-coming labs, so don't worry if you're unsure.. just give it a try!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 Business Idea:\n",
      "I’m here—what would you like help with? A bit more detail will let me jump in quickly.\n",
      "\n",
      "- Do you want me to write, summarize, explain, translate, or troubleshoot something?\n",
      "- If you have text, paste it and tell me what you want (summary, edit, tone, length, audience).\n",
      "- If it’s a problem to solve, share the goal, constraints, what you’ve tried, and any context (tools, deadlines).\n",
      "- If you’re brainstorming, tell me the topic, style, and how many ideas you want.\n",
      "\n",
      "Feel free to just paste “something here,” and I’ll suggest next steps.\n",
      "\n",
      "Iteration 2 Business Idea:\n",
      "Got it—you’ve got a “first message” prompt for an assistant, and you want it to guide users to give clear input. Your draft is helpful but a bit long and meta. Below are tighter, purpose-fit versions plus quick-reply ideas. Tell me where this will live (website chat, in‑product, email, support widget), your audience, and tone, and I’ll tailor.\n",
      "\n",
      "Ultra‑concise (general)\n",
      "- What can I help you do? Share your goal, context, and any examples.\n",
      "\n",
      "Friendly\n",
      "- I’m here to help—what are we working on? Paste your text or describe the task (write, edit, summarize, translate, troubleshoot). Add audience, tone, and any deadline.\n",
      "\n",
      "Professional\n",
      "- How can I assist? Please include your objective, constraints, relevant text or links, intended audience, tone, and timeframe.\n",
      "\n",
      "Brainstorming‑oriented\n",
      "- Topic + style + how many ideas? I’ll generate options and next steps.\n",
      "\n",
      "Troubleshooting‑oriented\n",
      "- What’s the issue, your goal, tools you're using, errors/logs, and what you’ve tried?\n",
      "\n",
      "Writer’s assistant\n",
      "- Paste your draft and tell me: desired outcome, audience, tone, length, and must‑include points.\n",
      "\n",
      "Support triage\n",
      "- Describe the problem, your account/org, product area, urgency, and screenshots or error codes.\n",
      "\n",
      "Website hero chat (CTA + examples)\n",
      "- What do you need done today? Try:\n",
      "  - “Summarize this report for execs”\n",
      "  - “Draft a 200‑word product update, friendly tone”\n",
      "  - “Debug this error in Node 18”\n",
      "  - “Brainstorm 10 tagline options”\n",
      "\n",
      "Quick‑reply chips (tap-to-start)\n",
      "- Write\n",
      "- Edit\n",
      "- Summarize\n",
      "- Translate\n",
      "- Brainstorm ideas\n",
      "- Fix a bug\n",
      "- Improve tone\n",
      "- Create an outline\n",
      "- Draft an email\n",
      "- Marketing copy\n",
      "\n",
      "Structured prompt template (users can fill blanks)\n",
      "- Goal:\n",
      "- Context/audience:\n",
      "- Tone/voice:\n",
      "- Length/format:\n",
      "- Constraints (tools, deadlines, word/character limits):\n",
      "- Input (paste text, links, code):\n",
      "- What you’ve tried (if troubleshooting):\n",
      "\n",
      "If you share:\n",
      "- Placement: website chat, app sidebar, email autoresponder, support bot\n",
      "- Audience: consumers, SMB, enterprise; technical/non-technical\n",
      "- Tone: friendly, formal, playful, authoritative\n",
      "- Any compliance/brand guidelines\n",
      "\n",
      "…I’ll deliver a finalized version, plus empty-state examples, quick replies, and follow-up logic.\n",
      "\n",
      "Iteration 3 Business Idea:\n",
      "Great concept. Here’s a ready-to-use starter pack you can drop into different surfaces now. If you share placement, audience, tone, and any constraints, I’ll tailor and tighten.\n",
      "\n",
      "Default (general first message)\n",
      "- What do you want to get done today? Share your goal, context, and any examples.\n",
      "\n",
      "Website chat (CTA + examples)\n",
      "- What do you need done today? Try:\n",
      "  - Summarize this doc for execs\n",
      "  - Draft a 150‑word product update, friendly tone\n",
      "  - Debug this error in Node 18\n",
      "  - Brainstorm 10 tagline options\n",
      "\n",
      "In‑product sidebar (writer + doer)\n",
      "- Paste your text or describe the task (write, edit, summarize, translate, troubleshoot). Add audience, tone, and any deadline.\n",
      "\n",
      "Support widget (triage)\n",
      "- Tell me the issue, your goal, product area, urgency, and what you’ve tried. Add screenshots or error codes if you have them.\n",
      "\n",
      "Email autoresponder (auto-reply assistant)\n",
      "- Subject: How can I help?\n",
      "- Reply with your objective, any constraints or deadlines, relevant links or files, audience, and preferred tone. I’ll send next steps.\n",
      "\n",
      "Quick‑reply chips (tap to start)\n",
      "- Write\n",
      "- Edit\n",
      "- Summarize\n",
      "- Translate\n",
      "- Brainstorm ideas\n",
      "- Fix a bug\n",
      "- Improve tone\n",
      "- Create an outline\n",
      "- Draft an email\n",
      "- Marketing copy\n",
      "\n",
      "Structured template (fillable)\n",
      "- Goal:\n",
      "- Audience/context:\n",
      "- Tone/voice:\n",
      "- Length/format:\n",
      "- Constraints (tools, deadlines, limits):\n",
      "- Input (paste text, links, code):\n",
      "- What you’ve tried (if troubleshooting):\n",
      "\n",
      "Follow‑up logic (first clarifying turn)\n",
      "- If user pastes text: Ask desired outcome, audience, tone, and length.\n",
      "- If task is vague: Offer 3 concrete options and ask which is closest.\n",
      "- If troubleshooting: Ask env/tools, exact error/logs, steps tried, and success criteria.\n",
      "- If brainstorming: Ask topic, style, constraints, and number of ideas.\n",
      "\n",
      "Tone swaps (pick one)\n",
      "- Friendly: I’m here to help—what are we working on?\n",
      "- Professional: How can I assist? Please include objective, context, and any constraints.\n",
      "- Playful: What’s on the docket? Toss me your goal and the vibe you want.\n",
      "\n",
      "To tailor, please share:\n",
      "- Placement (website chat, app sidebar, email, support)\n",
      "- Audience (consumer, SMB, enterprise; technical/non‑technical)\n",
      "- Tone (friendly, formal, playful, authoritative)\n",
      "- Languages/localization needs\n",
      "- UI limits (character counts) and any brand/compliance guidelines\n",
      "\n",
      "I can also deliver empty‑state examples, A/B variants, and brief UX copy for edge cases (no input, long input, private info warnings).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n",
    "\n",
    "# First create the messages:\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"Something here\"}]\n",
    "for i in range(3):  # repeat N times\n",
    "    # Step 2: Make the call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    " \n",
    "# Then read the business idea:\n",
    "\n",
    " # Step 3: Read out the business idea\n",
    "    business_idea = response.choices[0].message.content\n",
    "    print(f\"Iteration {i+1} Business Idea:\\n{business_idea}\\n\")\n",
    "\n",
    "\n",
    "# And repeat! In the next message, include the business idea within the message\n",
    "\n",
    "    # Step 4: Feed the idea into the next message\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Here is the business idea: {business_idea}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 1: Industry Pick ===\n",
      "{\n",
      "  \"industry\": \"Healthcare AI\",\n",
      "  \"why_now\": \"Rapid advancements in AI enable personalized diagnostics and treatment automation, improving healthcare outcomes and reducing costs.\",\n",
      "  \"market_signals\": [\n",
      "    \"Growing investment in AI-driven healthcare startups\",\n",
      "    \"Increasing demand for telemedicine and remote patient monitoring solutions\",\n",
      "    \"Regulatory bodies approving AI-based diagnostic tools\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "=== Step 2: Pain Point ===\n",
      "{\n",
      "  \"pain_point\": \"Difficulty in rapidly customizing AI models for diverse client needs\",\n",
      "  \"who_it_hurts\": [\n",
      "    \"AI consultants\",\n",
      "    \"Client project managers\"\n",
      "  ],\n",
      "  \"current_workaround\": \"Manual adaptation of pre-built AI models which is time-consuming and error-prone\",\n",
      "  \"constraints\": [\n",
      "    \"Client data privacy regulations\",\n",
      "    \"Integration with legacy systems\"\n",
      "  ],\n",
      "  \"success_kpis\": [\n",
      "    \"Reduction in model customization time\",\n",
      "    \"Increase in client project throughput\",\n",
      "    \"Improvement in model accuracy post-deployment\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "=== Step 3: Agentic Solution ===\n",
      "{\n",
      "  \"solution_name\": \"MedAdapt AI\",\n",
      "  \"core_agents\": [\n",
      "    \"Data Privacy Compliance Agent\",\n",
      "    \"Automated Model Customization Agent\"\n",
      "  ],\n",
      "  \"key_capabilities\": [\n",
      "    \"Automated adaptation of AI models based on client-specific medical datasets with built-in privacy safeguards\",\n",
      "    \"Seamless integration with legacy healthcare systems through modular connectors\"\n",
      "  ],\n",
      "  \"business_model\": \"Subscription-based SaaS with tiered pricing based on customization volume and support level\",\n",
      "  \"competitive_advantage\": \"Combines fully automated, privacy-compliant model customization with legacy system compatibility, drastically reducing time and errors in deployment\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def jget(txt):\n",
    "    \"\"\"Extract JSON object from a model response safely.\"\"\"\n",
    "    # Try direct parse first\n",
    "    try:\n",
    "        return json.loads(txt)\n",
    "    except Exception:\n",
    "        # Fallback: find the first {...} block\n",
    "        start = txt.find(\"{\")\n",
    "        end   = txt.rfind(\"}\")\n",
    "        if start != -1 and end != -1 and end > start:\n",
    "            return json.loads(txt[start:end+1])\n",
    "        raise ValueError(\"No JSON object found in response\")\n",
    "\n",
    "SYSTEM = (\n",
    "    \"You are a precise product strategist. \"\n",
    "    \"Always respond in compact JSON, no prose.\"\n",
    ")\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"Something here\"}]\n",
    "\n",
    "# ---- Call 1: Pick a business area worth exploring ----\n",
    "prompt_industry = \"\"\"\n",
    "Pick one commercial business area that looks promising for an Agentic AI opportunity.\n",
    "Return JSON:\n",
    "{\n",
    "  \"industry\": \"AI CONSULTING\",\n",
    "  \"why_now\": \"WOULD LIKE TO EARN LOT OF MONEY\",\n",
    "  \"market_signals\": [\"<signal1>\", \"<signal2>\"]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "r1 = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        *messages,\n",
    "        {\"role\": \"user\", \"content\": prompt_industry.strip()}\n",
    "    ]\n",
    ")\n",
    "industry_obj = jget(r1.choices[0].message.content)\n",
    "industry = industry_obj[\"industry\"]\n",
    "\n",
    "# industry_obj = jget(r1.choices[0].message.content)\n",
    "# industry = industry_obj[\"industry\"]\n",
    "# industry_obj = jget(r1.output_text)\n",
    "# industry = industry_obj[\"industry\"]\n",
    "\n",
    "# Feed the “business idea” into the next message (as you requested)\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": f\"Business idea industry: {industry}. Context: {json.dumps(industry_obj)}\"\n",
    "})\n",
    "\n",
    "# ---- Call 2: Surface a painful problem in that industry ----\n",
    "pprompt_pain = f\"\"\"\n",
    "Given the industry \"{industry}\", present ONE acute pain point that is ripe for an Agentic AI solution.\n",
    "Return JSON:\n",
    "{{\n",
    "  \"pain_point\": \"DESCRIPTION OF THE PAIN\",\n",
    "  \"who_feels_it\": \"WHO FEELS THIS PAIN\",\n",
    "  \"current_solutions\": [\"<current_solution1>\", \"<current_solution2>\"]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "r2 = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        *messages,\n",
    "        {\"role\": \"user\", \"content\": prompt_pain.strip()}\n",
    "    ]\n",
    ")\n",
    "pain_obj = jget(r2.choices[0].message.content)\n",
    "pain = pain_obj[\"pain_point\"]\n",
    "\n",
    "\n",
    "# Include the extracted idea in the very next message\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": f\"Industry: {industry}. Pain point: {pain}. Full context: {json.dumps(pain_obj)}\"\n",
    "})\n",
    "\n",
    "# ---- Call 3: Propose the agentic solution ----\n",
    "prompt_solution = f\"\"\"\n",
    "Propose an Agentic AI solution for industry \"{industry}\" addressing pain \"{pain}\".\n",
    "Return JSON:\n",
    "{{\n",
    "  \"solution_name\": \"NAME OF THE SOLUTION\",\n",
    "  \"core_agents\": [\"<agent1>\", \"<agent2>\"],\n",
    "  \"key_capabilities\": [\"<capability1>\", \"<capability2>\"],\n",
    "  \"business_model\": \"HOW IT MAKES MONEY\",\n",
    "  \"competitive_advantage\": \"WHY THIS WILL WIN\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "r3 = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        *messages,\n",
    "        {\"role\": \"user\", \"content\": prompt_solution.strip()}\n",
    "    ]\n",
    ")\n",
    "solution_obj = jget(r3.choices[0].message.content)\n",
    "\n",
    "# ---- Pretty print results ----\n",
    "print(\"\\n=== Step 1: Industry Pick ===\")\n",
    "print(json.dumps(industry_obj, indent=2))\n",
    "\n",
    "print(\"\\n=== Step 2: Pain Point ===\")\n",
    "print(json.dumps(pain_obj, indent=2))\n",
    "\n",
    "print(\"\\n=== Step 3: Agentic Solution ===\")\n",
    "print(json.dumps(solution_obj, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
