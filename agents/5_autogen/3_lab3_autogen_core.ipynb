{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now - Week 3 Day 3\n",
    "\n",
    "## AutoGen Core\n",
    "\n",
    "Something a little different.\n",
    "\n",
    "This is agnostic to the underlying Agent framework\n",
    "\n",
    "You can use AutoGen AgentChat, or you can use something else; it's an Agent interaction framework.\n",
    "\n",
    "From that point of view, it's positioned similarly to LangGraph.\n",
    "\n",
    "### The fundamental principle\n",
    "\n",
    "Autogen Core decouples an agent's logic from how messages are delivered.  \n",
    "The framework provides a communication infrastructure, along with agent lifecycle, and the agents are responsible for their own work.\n",
    "\n",
    "The communication infrastructure is called a Runtime.\n",
    "\n",
    "There are 2 types: **Standalone** and **Distributed**.\n",
    "\n",
    "Today we will use a standalone runtime: the **SingleThreadedAgentRuntime**, a local embedded agent runtime implementation.\n",
    "\n",
    "Tomorrow we'll briefly look at a Distributed runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from autogen.agentchat import AssistantAgent\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Note: autogen_core and autogen_agentchat modules don't exist in current AutoGen\n",
    "# Using available modules instead\n",
    "\n",
    "# Create custom classes since autogen_core doesn't exist\n",
    "class AgentId:\n",
    "    def __init__(self, agent_type: str, key: str):\n",
    "        self.type = agent_type\n",
    "        self.key = key\n",
    "\n",
    "class MessageContext:\n",
    "    def __init__(self):\n",
    "        self.cancellation_token = None\n",
    "\n",
    "class RoutedAgent:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.id = AgentId(\"agent\", name)\n",
    "    \n",
    "    @classmethod\n",
    "    async def register(cls, runtime, agent_type, factory):\n",
    "        \"\"\"Register an agent with the runtime\"\"\"\n",
    "        agent = factory()\n",
    "        agent.runtime = runtime  # Store runtime reference\n",
    "        \n",
    "        # Handle different runtime types\n",
    "        if hasattr(runtime, 'agents'):\n",
    "            # SingleThreadedAgentRuntime\n",
    "            runtime.agents[agent_type] = agent\n",
    "            print(f\"‚úÖ Registered agent: {agent_type}\")\n",
    "        elif hasattr(runtime, 'register'):\n",
    "            # GrpcWorkerAgentRuntime - use its register method\n",
    "            await runtime.register(agent_type, lambda: agent)\n",
    "        else:\n",
    "            # Fallback - try to set agents attribute\n",
    "            if not hasattr(runtime, 'agents'):\n",
    "                runtime.agents = {}\n",
    "            runtime.agents[agent_type] = agent\n",
    "            print(f\"‚úÖ Registered agent: {agent_type}\")\n",
    "        \n",
    "        return agent\n",
    "    \n",
    "    async def send_message(self, message: \"Message\", agent_id: AgentId) -> \"Message\":\n",
    "        \"\"\"Send a message to another agent via the runtime\"\"\"\n",
    "        if not hasattr(self, 'runtime') or self.runtime is None:\n",
    "            return Message(content=\"‚ùå No runtime available\")\n",
    "        return await self.runtime.send_message(message, agent_id)\n",
    "\n",
    "def message_handler(func):\n",
    "    return func\n",
    "\n",
    "class SingleThreadedAgentRuntime:\n",
    "    def __init__(self):\n",
    "        self.agents = {}\n",
    "        self.running = False\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start the runtime\"\"\"\n",
    "        self.running = True\n",
    "        print(\"üöÄ Runtime started\")\n",
    "    \n",
    "    async def stop(self):\n",
    "        \"\"\"Stop the runtime\"\"\"\n",
    "        self.running = False\n",
    "        print(\"‚èπÔ∏è Runtime stopped\")\n",
    "    \n",
    "    async def close(self):\n",
    "        \"\"\"Close the runtime\"\"\"\n",
    "        self.agents.clear()\n",
    "        print(\"üîí Runtime closed\")\n",
    "    \n",
    "    async def send_message(self, message, agent_id):\n",
    "        \"\"\"Send a message to a specific agent\"\"\"\n",
    "        if not self.running:\n",
    "            print(\"‚ö†Ô∏è Runtime not started\")\n",
    "            return message\n",
    "        \n",
    "        # Try different key formats for agent lookup\n",
    "        agent_key = f\"{agent_id.type}_{agent_id.key}\" if hasattr(agent_id, 'type') else str(agent_id)\n",
    "        agent = self.agents.get(agent_key)\n",
    "        \n",
    "        # If not found, try just the type (for cases where agent is registered by type only)\n",
    "        if not agent:\n",
    "            agent = self.agents.get(agent_id.type)\n",
    "        \n",
    "        # If still not found, try just the key\n",
    "        if not agent:\n",
    "            agent = self.agents.get(agent_id.key)\n",
    "        \n",
    "        # Debug: Print available agents\n",
    "        if not agent:\n",
    "            print(f\"‚ùå Agent {agent_key} not found\")\n",
    "            print(f\"Available agents: {list(self.agents.keys())}\")\n",
    "            print(f\"Looking for: type='{agent_id.type}', key='{agent_id.key}'\")\n",
    "            return Message(content=f\"Agent {agent_key} not found\")\n",
    "        \n",
    "        # Create message context\n",
    "        ctx = MessageContext()\n",
    "        \n",
    "        # Find and call the appropriate message handler\n",
    "        if hasattr(agent, 'on_my_message'):\n",
    "            response = await agent.on_my_message(message, ctx)\n",
    "        elif hasattr(agent, 'handle_my_message_type'):\n",
    "            response = await agent.handle_my_message_type(message, ctx)\n",
    "        else:\n",
    "            response = Message(content=f\"Agent {agent.name} received: {message.content}\")\n",
    "        \n",
    "        return response\n",
    "\n",
    "class TextMessage:\n",
    "    def __init__(self, content: str, source: str = \"user\"):\n",
    "        self.content = content\n",
    "        self.source = source\n",
    "\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we define our Message object\n",
    "\n",
    "Whatever structure we want for messages in our Agent framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a simple one!\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    content: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we define our Agent\n",
    "\n",
    "A subclass of RoutedAgent.\n",
    "\n",
    "Every Agent has an **Agent ID** which has 2 components:  \n",
    "`agent.id.type` describes the kind of agent it is  \n",
    "`agent.id.key` gives it its unique identifier\n",
    "\n",
    "Any method with the `@message_handler` decorated will have the opportunity to receive messages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAgent(RoutedAgent):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"Simple\")\n",
    "\n",
    "    @message_handler\n",
    "    async def on_my_message(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        return Message(content=f\"This is {self.id.type}-{self.id.key}. You said '{message.content}' and I disagree.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK let's create a Standalone runtime and register our agent type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "# Simplified registration for demonstration\n",
    "agent = SimpleAgent()\n",
    "runtime.agents[\"player1\"] = agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alright! Let's start a runtime and send a message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Runtime started\n"
     ]
    }
   ],
   "source": [
    "runtime.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> This is agent-Simple. You said 'Well hi there!' and I disagree.\n"
     ]
    }
   ],
   "source": [
    "agent_id = AgentId(\"player1\", \"player1\")\n",
    "response = await runtime.send_message(Message(\"Well hi there!\"), agent_id)\n",
    "print(\">>>\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚èπÔ∏è Runtime stopped\n",
      "üîí Runtime closed\n"
     ]
    }
   ],
   "source": [
    "await runtime.stop()\n",
    "await runtime.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK Now let's do something more interesting\n",
    "\n",
    "We'll use an AgentChat Assistant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyLLMAgent(RoutedAgent):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"LLMAgent\")\n",
    "        self._delegate = AssistantAgent(\n",
    "            \"LLMAgent\", \n",
    "            llm_config={\n",
    "                \"model\": \"gpt-4.1-mini\",\n",
    "                \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "                \"price\": [0.00015, 0.0006]  # Add pricing to prevent warning\n",
    "            }\n",
    "        )\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        print(f\"{self.id.type} received message: {message.content}\")\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = self._delegate.generate_reply([{\"role\": \"user\", \"content\": message.content}])\n",
    "        reply = response\n",
    "        print(f\"{self.id.type} responded: {reply}\")\n",
    "        return Message(content=reply)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agents registered successfully!\n",
      "Registered agents: ['agent_Simple', 'agent_LLMAgent']\n"
     ]
    }
   ],
   "source": [
    "# Note: autogen_core doesn't exist in current AutoGen version\n",
    "# Using our custom SingleThreadedAgentRuntime implementation\n",
    "\n",
    "# Create runtime instance\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "\n",
    "# Register agents (simplified for demonstration)\n",
    "simple_agent = SimpleAgent()\n",
    "llm_agent = MyLLMAgent()\n",
    "\n",
    "# Store agents in runtime with correct key format\n",
    "runtime.agents[\"agent_Simple\"] = simple_agent\n",
    "runtime.agents[\"agent_LLMAgent\"] = llm_agent\n",
    "\n",
    "print(\"‚úÖ Agents registered successfully!\")\n",
    "print(f\"Registered agents: {list(runtime.agents.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Runtime started\n",
      "agent received message: Hi there!\n",
      "agent responded: Hello! How can I assist you today?\n",
      ">LLMAgent>> Hello! How can I assist you today?\n",
      ">>Simple>> This is agent-Simple. You said 'Hello! How can I assist you today?' and I disagree.\n",
      "agent received message: This is agent-Simple. You said 'Hello! How can I assist you today?' and I disagree.\n",
      "agent responded: I understand you disagree with the greeting I used. Could you please clarify how you would prefer me to greet you or assist you? This will help me tailor my responses to your preferences.\n",
      ">>LLMAgent>> I understand you disagree with the greeting I used. Could you please clarify how you would prefer me to greet you or assist you? This will help me tailor my responses to your preferences.\n"
     ]
    }
   ],
   "source": [
    "runtime.start()  # Start processing messages in the background.\n",
    "\n",
    "# Send messages between agents\n",
    "response = await runtime.send_message(Message(\"Hi there!\"), AgentId(\"agent\", \"LLMAgent\"))\n",
    "print(\">LLMAgent>>\", response.content)\n",
    "\n",
    "response = await runtime.send_message(Message(response.content), AgentId(\"agent\", \"Simple\"))\n",
    "print(\">>Simple>>\", response.content)\n",
    "\n",
    "response = await runtime.send_message(Message(response.content), AgentId(\"agent\", \"LLMAgent\"))\n",
    "print(\">>LLMAgent>>\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚èπÔ∏è Runtime stopped\n",
      "üîí Runtime closed\n"
     ]
    }
   ],
   "source": [
    "await runtime.stop()\n",
    "await runtime.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK now let's show this at work - let's have 3 agents interact!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: autogen_ext.models.ollama doesn't exist in current AutoGen version\n",
    "# Using AssistantAgent with OpenAI instead\n",
    "\n",
    "class Player1Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        self._delegate = AssistantAgent(\n",
    "            name,\n",
    "            llm_config={\n",
    "                \"model\": \"gpt-4.1-mini\",\n",
    "                \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "                \"price\": [0.00015, 0.0006],  # Add pricing to prevent warning\n",
    "                \"temperature\": 1.0\n",
    "            }\n",
    "        )\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = self._delegate.generate_reply([{\"role\": \"user\", \"content\": message.content}])\n",
    "        return Message(content=response)\n",
    "    \n",
    "class Player2Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        self._delegate = AssistantAgent(\n",
    "            name, \n",
    "            llm_config={\n",
    "                \"model\": \"llama3.2\",\n",
    "                \"api_key\": \"ollama\",  # Ollama doesn't require a real API key\n",
    "                \"temperature\": 1.0,\n",
    "                \"base_url\": \"http://192.168.2.118:1234/v1\"  # Ollama API endpoint\n",
    "            }\n",
    "        )\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = self._delegate.generate_reply([{\"role\": \"user\", \"content\": message.content}])\n",
    "        return Message(content=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "JUDGE = \"You are judging a game of rock, paper, scissors. The players have made these choices:\\n\"\n",
    "\n",
    "class RockPaperScissorsAgent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        self._delegate = AssistantAgent(\n",
    "            name, \n",
    "            llm_config={\n",
    "                \"model\": \"gpt-4.1-mini\",\n",
    "                \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "                \"price\": [0.00015, 0.0006],  # Add pricing to prevent warning\n",
    "                \"temperature\": 1.0\n",
    "            }\n",
    "        )\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        instruction = \"You are playing rock, paper, scissors. Respond only with the one word, one of the following: rock, paper, or scissors.\"\n",
    "        message = Message(content=instruction)\n",
    "        inner_1 = AgentId(\"player1\", \"player1\")\n",
    "        inner_2 = AgentId(\"player2\", \"player2\")\n",
    "        response1 = await self.send_message(message, inner_1)\n",
    "        response2 = await self.send_message(message, inner_2)\n",
    "        result = f\"Player 1: {response1.content}\\nPlayer 2: {response2.content}\\n\"\n",
    "        judgement = f\"{JUDGE}{result}Who wins?\"\n",
    "        message = TextMessage(content=judgement, source=\"user\")\n",
    "        response = self._delegate.generate_reply([{\"role\": \"user\", \"content\": judgement}])\n",
    "        return Message(content=result + response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Registered agent: player1\n",
      "‚úÖ Registered agent: player2\n",
      "‚úÖ Registered agent: rock_paper_scissors\n",
      "üöÄ Runtime started\n"
     ]
    }
   ],
   "source": [
    "runtime = SingleThreadedAgentRuntime()\n",
    "await Player1Agent.register(runtime, \"player1\", lambda: Player1Agent(\"player1\"))\n",
    "await Player2Agent.register(runtime, \"player2\", lambda: Player2Agent(\"player2\"))\n",
    "await RockPaperScissorsAgent.register(runtime, \"rock_paper_scissors\", lambda: RockPaperScissorsAgent(\"rock_paper_scissors\"))\n",
    "runtime.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1: rock\n",
      "Player 2: {'content': 'rock', 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': []}\n",
      "The choices for the players are:\n",
      "\n",
      "Player 1: rock\n",
      "Player 2: rock\n",
      "\n",
      "Since both players chose rock, the game is a tie. There is no winner. \n",
      "\n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "agent_id = AgentId(\"rock_paper_scissors\", \"rock_paper_scissors\")\n",
    "message = Message(content=\"go\")\n",
    "response = await runtime.send_message(message, agent_id)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚èπÔ∏è Runtime stopped\n",
      "üîí Runtime closed\n"
     ]
    }
   ],
   "source": [
    "await runtime.stop()\n",
    "await runtime.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
